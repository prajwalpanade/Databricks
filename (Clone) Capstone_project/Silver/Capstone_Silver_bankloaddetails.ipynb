{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "96e898e0-efa6-4108-bfcb-b31388ec36bf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Importing important function\n",
    "import os\n",
    "from datetime import datetime\n",
    "import time\n",
    "from pyspark.sql.types import StructType, StructField, StringType, DoubleType, TimestampType, IntegerType\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b8a0123c-1e4d-4ee2-a6c2-43a2e71b9f26",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "# Define paths for bronze and silver zones\n",
    "bronze_path = \"/mnt/Prajwal/Capstone_Project/bronze/bankloandetails\"\n",
    "silver_path = \"/mnt/Prajwal/Capstone_Project/silver/bankloandetails\"\n",
    "\n",
    "df_bronze = spark.read.parquet(bronze_path)\n",
    "\n",
    "# Rename columns\n",
    "df_bronze = df_bronze.withColumnRenamed(\"Loan ID\", \"loan_id\") \\\n",
    "                     .withColumnRenamed(\"customer ID\", \"customer_id\") \\\n",
    "                     .withColumnRenamed(\"Current Loan Amount\", \"current_loan_amount\") \\\n",
    "                     .withColumnRenamed(\"Credit Score\", \"credit_score\") \\\n",
    "                     .withColumnRenamed(\"annual income\", \"annual_income\") \\\n",
    "                     .withColumnRenamed(\"years in current job\", \"years_in_current_job\") \\\n",
    "                     .withColumnRenamed(\"home ownership\", \"home_ownership\") \\\n",
    "                     .withColumnRenamed(\"loan_start_dt  \", \"loan_start_date\")\n",
    "\n",
    "# Fill missing values\n",
    "df_bronze = df_bronze.fillna({\n",
    "    \"credit_score\": 0,\n",
    "    \"annual_income\": 0,\n",
    "    \"home_ownership\": \"Unknown\",\n",
    "    \"purpose\": \"Unknown\"\n",
    "})\n",
    "\n",
    "# Remove negative sign from current_loan_amount\n",
    "df_bronze = df_bronze.withColumn(\"current_loan_amount\", regexp_replace(col(\"current_loan_amount\"), \"^-\", \"\"))\n",
    "\n",
    "# Cast columns to appropriate data types\n",
    "df_bronze = df_bronze.withColumn(\"current_loan_amount\", col(\"current_loan_amount\").cast(\"decimal(10,2)\"))\n",
    "df_bronze = df_bronze.withColumn(\"annual_income\", col(\"annual_income\").cast(\"decimal(10,2)\"))\n",
    "\n",
    "# Handle invalid values in current_loan_amount and annual_income\n",
    "df_bronze = df_bronze.withColumn(\"current_loan_amount\", when(col(\"current_loan_amount\") < 900, 0).otherwise(col(\"current_loan_amount\")))\n",
    "df_bronze = df_bronze.withColumn(\"annual_income\", when(col(\"annual_income\") < 0, 0).otherwise(col(\"annual_income\")))\n",
    "\n",
    "# Standardize home_ownership column\n",
    "df_bronze = df_bronze.withColumn(\n",
    "    \"home_ownership\",\n",
    "    when(lower(trim(col(\"home_ownership\"))).contains(\"mortgage\"), lit(\"Home Mortgage\"))\n",
    "    .when(lower(trim(col(\"home_ownership\"))).contains(\"rent\"), lit(\"Rent\"))\n",
    "    .when(lower(trim(col(\"home_ownership\"))).contains(\"own\"), lit(\"Own Home\"))\n",
    "    .otherwise(lit(\"Unknown\"))\n",
    ")\n",
    "\n",
    "# Handle 'N/A' in years_in_current_job\n",
    "df_bronze = df_bronze.withColumn(\"years_in_current_job\", when(lower(col(\"years_in_current_job\")) == \"n/a\", 0).otherwise(col(\"years_in_current_job\")))\n",
    "\n",
    "# Create credit_category column\n",
    "df_bronze = df_bronze.withColumn(\n",
    "    \"credit_category\",\n",
    "    when(col(\"credit_score\") < 580, \"Poor\")\n",
    "    .when((col(\"credit_score\") >= 580) & (col(\"credit_score\") <= 669), \"Fair\")\n",
    "    .when((col(\"credit_score\") >= 670) & (col(\"credit_score\") <= 739), \"Good\")\n",
    "    .when((col(\"credit_score\") >= 740) & (col(\"credit_score\") <= 799), \"Very Good\")\n",
    "    .when(col(\"credit_score\") >= 800, \"Exceptional\")\n",
    "    .otherwise(None)\n",
    ")\n",
    "\n",
    "# Parse loan_start_date with multiple date formats\n",
    "df_bronze = df_bronze.withColumn(\n",
    "    \"loan_start_date\",\n",
    "    coalesce(\n",
    "        to_date(col(\"loan_start_date\"), \"d-MMM-yy\"),\n",
    "        to_date(col(\"loan_start_date\"), \"M/d/yyyy\"),\n",
    "        to_date(col(\"loan_start_date\"), \"MMM dd-yyyy\"),\n",
    "        to_date(col(\"loan_start_date\"), \"yyyy-MM-dd\"),\n",
    "        to_date(col(\"loan_start_date\"), \"MMMM dd, yyyy\"),\n",
    "        to_date(col(\"loan_start_date\"), \"MM/dd/yyyy\"),\n",
    "        to_date(col(\"loan_start_date\"), \"MMM-dd/yyyy\"),\n",
    "        to_date(col(\"loan_start_date\"), \"MMM-d/yyyy\")\n",
    "    )\n",
    ")\n",
    "\n",
    "df_bronze = df_bronze.withColumn(\"loan_start_date_flag\", when(df_bronze.loan_start_date.isNull(), lit(\"missing\")).otherwise(lit(\"present\")))\n",
    "\n",
    "# Clean the target path before writing\n",
    "dbutils.fs.rm(silver_path, True)\n",
    "\n",
    "# Write to Silver layer Delta format\n",
    "df_bronze.write.format(\"delta\").mode(\"overwrite\").save(silver_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ae56b1cc-e152-4961-91a2-951d37ef3ce8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Read from Silver layer delta form\n",
    "\n",
    "df_silver = spark.read.format(\"delta\").load(silver_path)\n",
    "display(df_silver)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "82e1e066-1142-4f6e-91fd-ab07bf4e505a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Capstone_Silver_bankloaddetails",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
