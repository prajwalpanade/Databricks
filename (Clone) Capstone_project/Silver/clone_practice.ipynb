{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6ccc53c3-97de-4e51-8d23-9b20440df2fb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# import imporant libraries\n",
    "from pyspark.sql.functions import col, regexp_extract, regexp_replace, floor, datediff, current_date, to_date, lit, current_timestamp\n",
    "from pyspark.sql.types import DateType\n",
    "from delta.tables import DeltaTable\n",
    "from pyspark.sql.functions import date_format\n",
    "from delta.tables import DeltaTable\n",
    "from pyspark.sql.functions import col, regexp_extract, regexp_replace, date_format, current_timestamp, lit, floor, datediff, to_date\n",
    "from pyspark.sql.types import DateType\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a417e80e-dbc6-4677-afc8-7c005f919c0e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "bronze_path_day0 = \"/mnt/Prajwal/Capstone_Project/bronze/bankcustomer_source1_day0\"\n",
    "silver_path = \"/mnt/Prajwal/Capstone_Project/silver/bankcustomer_source_clone1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "969bdd8e-a330-4e25-a4c6-3cb18688afdb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = spark.read.format(\"parquet\").option(\"inferSchema\", \"true\").load(bronze_path_day0)\n",
    "\n",
    "# Drop the last 2 rows of the DataFrame\n",
    "df = df.limit(df.count() - 2)\n",
    "\n",
    "# Trim spaces from column names\n",
    "df = df.toDF(*[c.strip() for c in df.columns])\n",
    "\n",
    "# Rename columns for consistency and readability\n",
    "df = df.withColumnRenamed(\"_Customerid\", \"customer_id\") \\\n",
    "       .withColumnRenamed(\"C1ustomer Name\", \"name\") \\\n",
    "       .withColumnRenamed(\"City\", \"city\") \\\n",
    "       .withColumnRenamed(\"Phoneno\", \"phone_no\") \\\n",
    "       .withColumnRenamed(\"Maritial_Status\", \"maritial_status\") \\\n",
    "       .withColumnRenamed(\"Gender\", \"gender\") \\\n",
    "       .withColumnRenamed(\"EmailAddress\", \"email\")\n",
    "\n",
    "# Fill null values with default values\n",
    "df = df.fillna({\n",
    "    'name': 'Unknown',\n",
    "    'city': 'Unknown',\n",
    "    'phone_no': '000-000-0000',\n",
    "    'maritial_status': 'Unknown',\n",
    "    'gender': 'Unknown',\n",
    "    'email': 'noemail@example.com'\n",
    "})\n",
    "\n",
    "# Extract area code from phone number\n",
    "df = df.withColumn(\"area_code\", regexp_extract(col(\"phone_no\"), r\"(\\d{3})\", 1))\n",
    "\n",
    "# Ensure email is correctly formatted\n",
    "df = df.withColumn('email', regexp_replace('email', r'[^a-zA-Z0-9@._-]', ''))\n",
    "\n",
    "# Change ingestion time to the format of yyyy-mm-dd hh:mm:ss\n",
    "df = df.withColumn('ingestion_time', date_format(col('ingest_time'), 'yyyy-MM-dd HH:mm:ss'))\n",
    "\n",
    "# Drop duplicate records based on customer_id\n",
    "df = df.dropDuplicates([\"customer_id\"])\n",
    "\n",
    "# Drop the original ingestion time column\n",
    "df = df.drop(\"ingest_time\")\n",
    "\n",
    "# Define a UDF to fix date of birth (DOB) format\n",
    "from pyspark.sql.functions import udf\n",
    "from datetime import datetime\n",
    "\n",
    "def fix_dob(dob_str):\n",
    "    try:\n",
    "        dob = datetime.strptime(dob_str, '%d-%b-%y')\n",
    "        if dob.year > datetime.today().year:\n",
    "            dob = dob.replace(year=dob.year - 100)\n",
    "        return dob\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "fix_dob_udf = udf(fix_dob, DateType())\n",
    "\n",
    "# Apply the UDF to fix DOB and calculate age\n",
    "df = df.withColumn(\"DOB\", fix_dob_udf(col(\"DOB\")))\n",
    "df_src1 = df.withColumn(\"age\", floor(datediff(current_date(), col(\"DOB\")) / 365.25))\n",
    "\n",
    "# Define paths for bronze source2 \n",
    "bronze_path = \"/mnt/Prajwal/Capstone_Project/bronze/bankcustomer_source2_day0\"\n",
    "\n",
    "# Read data from the bronze path\n",
    "df_src2 = spark.read.format(\"parquet\").load(bronze_path)\n",
    "\n",
    "# Rename columns for consistency and readability\n",
    "df_src2 = df_src2.withColumnRenamed(\"CustomerID\", \"customer_id\") \\\n",
    "       .withColumnRenamed(\"CustomerName\", \"name\") \\\n",
    "       .withColumnRenamed(\"City\", \"city\") \\\n",
    "       .withColumnRenamed(\"Phoneno\", \"phone_no\") \\\n",
    "       .withColumnRenamed(\"MaritalStatus\", \"maritial_status\") \\\n",
    "       .withColumnRenamed(\"Gender\", \"gender\") \\\n",
    "       .withColumnRenamed(\"EmailAddress\", \"email\")\n",
    "\n",
    "# Trim spaces from column names\n",
    "df_src2 = df_src2.toDF(*[c.strip() for c in df_src2.columns])\n",
    "\n",
    "# Extract area code from phone number\n",
    "df_src2 = df_src2.withColumn(\"area_code\", regexp_extract(col(\"phone_no\"), r\"^(\\d{3})\", 1))\n",
    "\n",
    "# Ensure email is correctly formatted\n",
    "df_src2 = df_src2.withColumn('email', regexp_replace('email', r'[^a-zA-Z0-9@._-]', ''))\n",
    "\n",
    "# Change ingestion time to the format of yyyy-mm-dd hh:mm:ss\n",
    "df_src2 = df_src2.withColumn('ingestion_time', date_format(col('ingest_time'), 'yyyy-MM-dd HH:mm:ss'))\n",
    "\n",
    "# Drop the original ingestion time column\n",
    "df_src2 = df_src2.drop(\"ingest_time\")\n",
    "\n",
    "# Drop duplicate records based on customer_id\n",
    "df_src2 = df_src2.dropDuplicates([\"customer_id\"])\n",
    "\n",
    "# Cast DOB to proper format\n",
    "df_src2 = df_src2.withColumn(\"DOB\", to_date(col(\"DOB\"), \"yyyy-MM-dd\"))\n",
    "\n",
    "# Calculate age\n",
    "df_src2 = df_src2.withColumn(\"age\", floor(datediff(current_date(), col(\"DOB\")) / 365.25))\n",
    "\n",
    "df_src2 = df_src2.select('customer_id',\n",
    " 'name',\n",
    " 'city',\n",
    " 'phone_no',\n",
    " 'maritial_status',\n",
    " 'gender',\n",
    " 'DOB',\n",
    " 'email',\n",
    " 'area_code',\n",
    " 'ingestion_time',\n",
    " 'age')\n",
    "\n",
    "df = df_src1.union(df_src2)\n",
    "\n",
    "df = df.withColumn(\"ingestion_time_formatted\", date_format(current_timestamp(), \"yyyy-MM-dd HH:mm:ss\"))\n",
    "\n",
    "\n",
    "df.write.mode(\"append\").format(\"delta\").option(\"overwriteSchema\", \"true\").save(silver_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3e3ab6bf-abd7-436e-88d4-729f5f140c9f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Read from silver path\n",
    "df_new = spark.read.format(\"delta\").load(silver_path)\n",
    "df_new.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9dde6608-56b5-4b4e-9fea-5fc7859ff7f8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "clone_practice",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
