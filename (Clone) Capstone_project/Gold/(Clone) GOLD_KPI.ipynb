{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eb84849b-fa9f-4e08-9219-22e9d0a88b0c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# import important libraries\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.window import Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fcec1f1a-2fb0-482a-a2ce-8a353b8fc18a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "customer_df = \"/mnt/Prajwal/Capstone_Project/Gold_clone/dim_customer\"\n",
    "\n",
    "loan_details_df = \"/mnt/Prajwal/Capstone_Project/Gold_clone/Dim_Loan_details\"\n",
    "\n",
    "customer_df = spark.read.format(\"delta\").load(customer_df)\n",
    "loan_details_df = spark.read.format(\"delta\").load(loan_details_df)\n",
    "\n",
    "display(customer_df)\n",
    "display(loan_details_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "517d0c0e-b6d0-4f0f-8d33-4d33855eb9ac",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Get the personal details of the customer who took loan for their wedding and are in rented house \n",
    "filtered_loans = loan_details_df.filter((lower(col(\"home_ownership\"))=='rent')&(lower(col('purpose'))=='wedding'))\n",
    "\n",
    "result_df = filtered_loans.join(customer_df, \"customer_id\", \"inner\")\n",
    "\n",
    "#result_df = result_df.select(\"customer_id\",\"Customer_Key\",\"city\",\"phone_no\",\"area_code\",\"marital_status\",\"gender\",\"dob\",\"age\",\"email\")\n",
    "\n",
    "display(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aeb70cd3-3918-4eaf-ad5a-58133737aac9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Calculate Payment Gap Days (the difference in days between consecutive payments).\n",
    "\n",
    "from pyspark.sql.functions import lag, datediff\n",
    "from pyspark.sql.window import Window\n",
    "payment_df = spark.read.format(\"delta\").load(\"/mnt/Prajwal/Prajwal/Retail_sales_usecase/gold/Fact_Payemnt\")\n",
    "pay_gap = payment_df.withColumn(\"prev_payment_date\", lag(col(\"payment_date\")).over(Window.partitionBy(\"loan_id\").orderBy(col(\"payment_date\"))))\n",
    "pay_gap = pay_gap.withColumn(\"payment_gap_days\", datediff(col(\"payment_date\"),col(\"prev_payment_date\")))\n",
    "pay_gap = pay_gap.select(\"loan_id\", \"customer_id\", \"payment_amount\", \"payment_date\", \"prev_payment_date\", \"payment_gap_days\")\n",
    "display(pay_gap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e1ee8c94-1ce1-407d-b147-88a3b2787462",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Find Customer Profitability. Categorize customers based on loan amounts, payments, penalties, and income.\n",
    "from pyspark.sql.functions import *\n",
    "loan_sums = loan_details_df.groupBy(\"customer_id\").agg(sum(\"current_loan_amount\").alias(\"total_loan_amount\"), avg(\"annual_income\").alias(\"avg_annual_income\"))\n",
    "payment_sums = payment_df.groupBy(\"loan_id\").agg(sum(\"payment_amount\").alias(\"total_payment_amount\"), \\\n",
    "    sum(\"penalty_amount\").alias(\"total_penalty_amount\")).join(loan_details_df.select(\"loan_id\", \"customer_id\"), on=\"loan_id\").groupBy(\"customer_id\").agg(sum(\"total_payment_amount\").alias(\"total_payments\"), \\\n",
    "    sum(\"total_penalty_amount\").alias(\"total_penalities\"))\n",
    "profitability_df = loan_sums.join(payment_sums, on='customer_id', how='outer').fillna(0)\n",
    "\n",
    "profitability_df = profitability_df.withColumn(\"profitability_score\", col(\"total_payments\")-col(\"total_penalities\")+(col(\"avg_annual_income\")*0.1)-(col(\"total_loan_amount\")*0.05))\n",
    "\n",
    "profitability_df = profitability_df.withColumn(\"profitability_category\", when(col(\"profitability_score\")> 0, \"Profitable\").otherwise(\"Unprofitable\"))\n",
    "display(profitability_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "59bfe3e3-28b5-4773-93fb-97bce67a26c8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Calculate Average Annual Loan Payment. (Consider the number of years the loan has been active.)\n",
    "loan_payment_summary = payment_df.groupBy(\"loan_id\").agg(sum(\"payment_amount\").alias(\"total_payments\"), min(\"payment_date\").alias(\"start_date\"), max(\"payment_date\").alias(\"end_date\"))\n",
    "\n",
    "loan_payment_summary = loan_payment_summary.withColumn(\"years_active\", (datediff(col(\"end_date\"), col(\"start_date\"))/lit(365.25)))\n",
    "\n",
    "loan_payment_summary = loan_payment_summary.withColumn(\"years_active\", when(col(\"years_active\")<1, 1).otherwise(col(\"years_active\")))\n",
    "average_annual_loan_payment_df = loan_payment_summary.withColumn(\"avg_annual_payment\", col(\"total_payments\")/col(\"years_active\"))\n",
    "\n",
    "display(average_annual_loan_payment_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b43bb923-d2c3-4562-9f88-a0b26b415098",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "(Clone) GOLD_KPI",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
