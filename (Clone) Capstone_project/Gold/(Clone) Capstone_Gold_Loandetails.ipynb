{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cd4d9c3e-f2af-4f1f-a1a0-a94e8b259250",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Importing the required libraries\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, DateType, StringType, DoubleType, TimestampType, BooleanType, DecimalType\n",
    "from delta.tables import DeltaTable\n",
    "from pyspark.sql.functions import current_timestamp, lit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cd43b7bb-d61a-4e50-923e-b3bea05ddf36",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Paths to the silver and gold layers\n",
    "silver_layer = \"/mnt/Prajwal/Capstone_Project/silver/bankloandetails\"\n",
    "gold_layer = \"/mnt/Prajwal/Capstone_Project/Gold_clone/dim_customer\"  # to compare customer data with loan deatils\n",
    "\n",
    "gold_path = \"/mnt/Prajwal/Capstone_Project/Gold_clone/Dim_Loan_details\"  # for loan deatil details \n",
    "\n",
    "# Checking missing records\n",
    "df_silver = spark.read.format(\"delta\").load(silver_layer)\n",
    "df_gold = spark.read.format(\"delta\").load(gold_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "334c1b18-017a-43e4-8764-3bcda7d9479a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Ignoring the orphan records\n",
    "\n",
    "missing_records = df_silver.join(df_gold, on=\"customer_id\", how=\"left\").filter(df_gold.customer_id.isNotNull()).select(df_silver.customer_id)\n",
    "\n",
    "display(missing_records)\n",
    "print(\"Total records in Loan details :\", df_silver.count())\n",
    "print(\"Total missing records in Customer Gold table but present in Loan details:\", missing_records.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4f6385ca-2fe8-42bc-a227-d08719103e0e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Drop duplicates in missing records\n",
    "missing_records = missing_records.dropDuplicates([\"customer_id\"])\n",
    "\n",
    "display(missing_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cabc5314-2239-44df-8d00-4bddd69dbc85",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Filter out records that have a matching customer_id in the Gold table using a left_semi join\n",
    "valid_customers_df = df_silver.join(\n",
    "    df_gold,\n",
    "    df_silver.customer_id == df_gold.customer_id,\n",
    "    how=\"left_semi\"\n",
    ")\n",
    "\n",
    "display(valid_customers_df)\n",
    "# Print the count of valid records\n",
    "print(\"Total valid records in Loan Details which has matching entry in Customer Gold table:\", valid_customers_df.count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5358ebe7-eb10-4ae6-a9c5-d51e4948bc65",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Drop duplicates based on 'customer_id' in the 'valid_customers_df' DataFrame\n",
    "valid_customers_df = valid_customers_df.dropDuplicates([\"customer_id\"])\n",
    "\n",
    "display(valid_customers_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6f136ab4-aca7-4d9e-afb9-4f134d2880b4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import lit, col, coalesce, max\n",
    "\n",
    "valid_customers_df = valid_customers_df.withColumn(\"loan_detail_key\", lit(None))\n",
    "max_key = valid_customers_df.agg(coalesce(max(\"loan_detail_key\"), lit(0))).collect()[0][0]\n",
    "\n",
    "display(valid_customers_df)\n",
    "display(max_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e278e063-3bbd-4f61-9756-a8cc510ce62f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "window_spec = Window.orderBy(\"Customer_Id\",\"Loan_Id\")\n",
    "valid_customers_df = valid_customers_df.withColumn(\"rn\", row_number().over(window_spec)) \\\n",
    "                                    .withColumn(\"loan_detail_key\", col(\"rn\") + lit(max_key)) \\\n",
    "                                    .drop(\"rn\")\n",
    "\n",
    "\n",
    "display(valid_customers_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d340684e-f00a-4026-9963-b513a6ada34d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "loan_schema = StructType([\n",
    "    StructField(\"loan_detail_key\", IntegerType(), True),\n",
    "    StructField(\"loan_id\", StringType(), True),\n",
    "    StructField(\"customer_id\", StringType(), True),\n",
    "    StructField(\"current_loan_amount\", DecimalType(10,2), True),\n",
    "    StructField(\"term\", StringType(), True),\n",
    "    StructField(\"credit_score\", StringType(), True),\n",
    "    StructField(\"credit_category\", StringType(), True),\n",
    "    StructField(\"annual_income\", DecimalType(10,2), True),\n",
    "    StructField(\"years_in_current_job\", StringType(), True),\n",
    "    StructField(\"home_ownership\", StringType(), True),\n",
    "    StructField(\"purpose\", StringType(), True),\n",
    "    StructField(\"loan_start_date\", DateType(), True),\n",
    "    StructField(\"start_date\", TimestampType(), True),\n",
    "    StructField(\"end_date\", TimestampType(), True),\n",
    "    StructField(\"is_active\", BooleanType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5022acf3-09cb-4fcf-97de-b16e07d60866",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "full_table_name=\"Prajwal.loan_details_dim\"\n",
    "\n",
    "try:\n",
    "    loan_details_dim = spark.read.format(\"delta\").load(gold_pathh)\n",
    "except:\n",
    "    empty_df = spark.createDataFrame([], loan_schema)\n",
    "    empty_df.write.format(\"delta\").mode(\"overwrite\").save(gold_path)\n",
    "    spark.sql(f\"CREATE TABLE IF NOT EXISTS {full_table_name} USING DELTA LOCATION '{gold_path}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b193c227-f9bf-4784-92d0-5abc02bbe555",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "loan_details_dim = DeltaTable.forPath(spark, gold_path)\n",
    "merge_condition = \"tgt.customer_id = src.customer_id AND tgt.is_active = true\"\n",
    "\n",
    "update_action = {\n",
    "    \"end_date\": current_timestamp(),\n",
    "    \"is_active\": lit(False)\n",
    "}\n",
    "\n",
    "insert_action = {\n",
    "    \"loan_detail_key\": \"src.loan_detail_key\",\n",
    "    \"loan_id\": \"src.loan_id\",\n",
    "    \"customer_id\": \"src.customer_id\",\n",
    "    \"current_loan_amount\": \"src.current_loan_amount\",\n",
    "    \"term\": \"src.term\",\n",
    "    \"credit_score\": \"src.credit_score\",\n",
    "    \"credit_category\": \"src.credit_category\",\n",
    "    \"annual_income\": \"src.annual_income\",\n",
    "    \"years_in_current_job\": \"src.years_in_current_job\",\n",
    "    \"home_ownership\": \"src.home_ownership\",\n",
    "    \"purpose\": \"src.purpose\",\n",
    "    \"loan_start_date\": \"src.loan_start_date\",\n",
    "    \"start_date\": current_timestamp(),\n",
    "    \"end_date\": lit(None).cast(TimestampType()),\n",
    "    \"is_active\": lit(True)\n",
    "}\n",
    "\n",
    "loan_details_dim_delta.alias(\"tgt\").merge(\n",
    "    valid_customers_df.alias(\"src\"),\n",
    "    merge_condition\n",
    ").whenMatchedUpdate(set=update_action) \\\n",
    " .whenNotMatchedInsert(values=insert_action) \\\n",
    " .execute()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0a5f575b-cdb3-48b9-9e41-b916f4995b6b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(\"select * from prajwal.loan_details_dim\").display()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "(Clone) Capstone_Gold_Loandetails",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
