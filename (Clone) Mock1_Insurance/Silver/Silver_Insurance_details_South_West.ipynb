{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "28bbdbc1-1284-4436-93a1-a0376530e62d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "silver zone is responsible for cleaning, standardization, and applying business rules.\n",
    "Auto Optimize & Small File Compaction (Delta Optimization)\n",
    "Memory & Shuffle Optimizations (if transformations occur)\n",
    "Data Deduplication (Removing Duplicates)\n",
    "Adjusting Shuffle Partitions & Enabling AQE\n",
    "Data Type Optimization (Ensuring efficient storage & performance)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ea99460d-4a80-4d41-ab04-9de3b5af2070",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Auto Optimize & Compact Small Files\n",
    "\n",
    "Enables Delta Lake's Auto Optimize whereever necessary.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "91d8f7a7-a7bd-4ef2-97d3-a6963f112e00",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(\"SET spark.databricks.delta.optimizeWrite.enabled = true\")\n",
    "spark.sql(\"SET spark.databricks.delta.autoCompact.enabled = true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b5a7999c-55bb-4f70-a74e-fd55f3836c5d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import substring\n",
    "from pyspark.sql.types import DateType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e79c5f8c-6fab-4760-8b9f-13bc73315af5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "bronze_path = \"/mnt/mock_prajwal/bronze/Insurance_details_South_0\"\n",
    "\n",
    "df = spark.read.format(\"parquet\").load(bronze_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "46509e0a-6ac8-46c9-a032-50f6f62d51ad",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = df.withColumnRenamed(\"Customer ID\", \"customer_id\") \\\n",
    "       .withColumnRenamed(\"Customer Name\", \"customer_name\") \\\n",
    "       .withColumnRenamed(\"Customer_Segment\", \"customer_segment\") \\\n",
    "       .withColumnRenamed(\"Maritial_Status\", \"marital_status\") \\\n",
    "       .withColumnRenamed(\"Gender\", \"gender\") \\\n",
    "       .withColumnRenamed(\"Effective_Start_Dt\", \"effective_start_date\") \\\n",
    "       .withColumnRenamed(\"Effective_End_Dt\", \"effective_end_date\") \\\n",
    "       .withColumnRenamed(\"Policy_Type_Id\", \"policy_type_id\") \\\n",
    "       .withColumnRenamed(\"Policy_Id\", \"policy_id\") \\\n",
    "       .withColumnRenamed(\"Premium_Amt\", \"premium_amount\") \\\n",
    "       .withColumnRenamed(\"Policy_Start_Dt\", \"policy_start_date\") \\\n",
    "       .withColumnRenamed(\"Policy_End_Dt\", \"policy_end_date\") \\\n",
    "       .withColumnRenamed(\"Next_Premium_Dt\", \"next_premium_date\") \\\n",
    "       .withColumnRenamed(\"Actual_Premium_Paid_Dt\", \"actual_premium_paid_date\") \\\n",
    "       .withColumnRenamed(\"Country\", \"country\") \\\n",
    "       .withColumnRenamed(\"Region\", \"region\") \\\n",
    "       .withColumnRenamed(\"State or Province\", \"state\") \\\n",
    "       .withColumnRenamed(\"City\", \"city\") \\\n",
    "       .withColumnRenamed(\"Postal Code\", \"postal_code\") \\\n",
    "       .withColumnRenamed(\"Total_Policy_Amt\", \"total_policy_amount\") \\\n",
    "       .withColumnRenamed(\"Premium_Amt_Paid_TillDate\", \"premium_amt_paid_tilldate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f25bf4ad-c186-4c1c-9867-a63247657d23",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from pyspark.sql.functions import udf, col\n",
    "from pyspark.sql.types import DateType\n",
    "from pyspark.sql.functions import col, datediff, to_date, floor\n",
    "from pyspark.sql.functions import lit, col, when\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import row_number\n",
    "from pyspark.sql.types import DateType\n",
    "\n",
    "def date_format_udf(date_str):\n",
    "    formats = ['%d-%b-%y', '%b %d-%Y', '%m/%d/%Y', '%m/_%d/%Y', '%m/ %b/%Y', '%d-%b-%Y', '%m/%d/%y' ,'%d-%m-%Y']\n",
    "\n",
    "    # Loop through each format to try parsing the string.\n",
    "    for fmt in formats:\n",
    "        try:\n",
    "            if date_str is None:\n",
    "                return None \n",
    "            \n",
    "            # Try parsing the string using the current format\n",
    "            date_obj = datetime.strptime(date_str, fmt)\n",
    "            current_date = datetime.now()\n",
    "            # If the parsed year is in the future, it's likely due to 2-digit year parsing (like '24' becoming 2124)\n",
    "            if date_obj.year > current_date.year:\n",
    "                # Correct it by subtracting 100 years\n",
    "                date_obj = date_obj.replace(year=date_obj.year - 100)\n",
    "            return date_obj.date()\n",
    "        except ValueError:\n",
    "            continue\n",
    "\n",
    "fix_dob_udf = udf(date_format_udf, DateType())\n",
    "\n",
    "df_new = df.withColumn(\"DOB\", fix_dob_udf(col(\"DOB\")))\n",
    "\n",
    "# Create a window specification\n",
    "window_spec = Window.orderBy(\"customer_id\")\n",
    "\n",
    "# Add row_number column\n",
    "df_new = df_new.withColumn(\"row_number\", row_number().over(window_spec))\n",
    "\n",
    "# Adjust DOB of 269 row to 1982-02-29 and 271 row to 1994-04-30 (since April has only 30 days)\n",
    "df_new = df_new.withColumn(\"DOB\", \n",
    "                           when(col(\"row_number\") == 269, lit(\"1982-02-29\").cast(DateType()))\n",
    "                           .when(col(\"row_number\") == 271, lit(\"1994-04-30\").cast(DateType()))\n",
    "                           .otherwise(col(\"DOB\")))\n",
    "\n",
    "df_new = df_new.drop(\"row_number\")\n",
    "\n",
    "df_new = df_new.withColumn(\"effective_start_date\", fix_dob_udf(col(\"effective_start_date\")))\n",
    "df_new = df_new.withColumn(\"effective_end_date\", fix_dob_udf(col(\"effective_end_date\")))\n",
    "\n",
    "df_new = df_new.withColumn(\"policy_start_date\", fix_dob_udf(col(\"policy_start_date\")))\n",
    "\n",
    "\n",
    "# Here this udf is for Policy end date \n",
    "\n",
    "def date_format_udf_Policy(date_str):\n",
    "    formats = ['%d-%b-%y', '%b %d-%Y', '%m/%d/%Y', '%m/_%d/%Y', '%m/ %b/%Y', '%d-%b-%Y', '%m/%d/%y' ,'%d-%m-%Y']\n",
    "\n",
    "    # Loop through each format to try parsing the string.\n",
    "    for fmt in formats:\n",
    "        try:\n",
    "            if date_str is None:\n",
    "                return None \n",
    "            \n",
    "            # Try parsing the string using the current format\n",
    "            date_obj = datetime.strptime(date_str, fmt)\n",
    "            current_date = datetime.now()\n",
    "            # If the parsed year is in the future, it's likely due to 2-digit year parsing (like '24' becoming 2124)\n",
    "            if date_obj.year > current_date.year:\n",
    "                # Correct it by subtracting 100 years\n",
    "                date_obj = date_obj.replace(year=date_obj.year)\n",
    "            return date_obj.date()\n",
    "        except ValueError:\n",
    "            continue\n",
    "\n",
    "fix_dob_udf_new = udf(date_format_udf_Policy, DateType())\n",
    "\n",
    "df_new = df_new.withColumn(\"policy_end_date\", fix_dob_udf_new(col(\"policy_end_date\")))\n",
    "\n",
    "df_new = df_new.withColumn(\"next_premium_date\", fix_dob_udf(col(\"next_premium_date\")))\n",
    "\n",
    "df_new = df_new.withColumn(\"actual_premium_paid_date\", fix_dob_udf(col(\"actual_premium_paid_date\")))\n",
    "\n",
    "# Standardize ZIP codes (Ensuring 5-digit numeric values)\n",
    "df_new = df_new.withColumn(\"postal_code\", regexp_replace(col(\"postal_code\"), \"[^0-9]\", \"\"))\n",
    "df_new = df_new.withColumn(\"postal_code\", lpad(col(\"postal_code\"), 5, \"0\"))\n",
    "df_new = df_new.withColumn(\"premium_amount\", col(\"premium_amount\").cast(\"integer\"))\n",
    "df_new = df_new.withColumn(\"total_policy_amount\", col(\"total_policy_amount\").cast(\"integer\"))\n",
    "df_new = df_new.withColumn(\"premium_amt_paid_tilldate\", col(\"premium_amt_paid_tilldate\").cast(\"integer\"))\n",
    "df_new = df_new.withColumn(\"country\", lit(\"USA\"))\n",
    "df_new = df_new.withColumn(\"region\", when(col(\"region\").isNull() | (col(\"region\") == \"\"), \"South\").otherwise(col(\"region\")))\n",
    "\n",
    "\n",
    "# df_new = df_new.withColumn(\"DOB\", to_date(col(\"DOB\"), \"yyyy-MM-dd\"))\n",
    "# df_new = df_new.withColumn(\"policy_start_date\", to_date(col(\"policy_start_date\"), \"yyyy-MM-dd\"))\n",
    "df_new = df_new.withColumn(\"age\", floor(datediff(col(\"policy_start_date\"), col(\"DOB\")) / 365))\n",
    "\n",
    "df_new = df_new.withColumn(\"effective_end_date\", col(\"policy_end_date\"))\n",
    "\n",
    "from pyspark.sql.functions import col, datediff, lit, floor\n",
    "\n",
    "# Assuming 'customer_start_date' is the column indicating when the customer started\n",
    "df_new = df_new.withColumn(\"customer_tenure_years\", \n",
    "                           floor(datediff(col(\"actual_premium_paid_date\"), col(\"policy_start_date\")) / 365).alias(\"customer_tenure_years\"))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cf2b4fa3-6c1b-4ce6-a9c3-ba82e8134fb1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "Named_df = df_new.withColumn(\"customer_name\",regexp_replace(col(\"customer_name\"),r\"(?i)^\\s*doctor\\s+\",\"Dr.\")).withColumn(\"customer_name\",regexp_replace(col(\"customer_name\"),r\"(?i)^\\s+professor\\s+\",\"Prof.\")).\\\n",
    "withColumn(\"customer_name\",regexp_replace(col(\"customer_name\"),r\"(?i)^\\s*Mistress\\s*\",\"Mrs\")) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "29a0f56a-21b5-49a5-9c9e-5826cf3c7c05",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "Named_final = Named_df.withColumn(\"customer_name\",regexp_replace(col(\"customer_name\"),r\"(?i)^\\s*doctor\\s*\",\"Dr\")). \\\n",
    "withColumn(\"customer_name\",regexp_replace(col(\"customer_name\"),r\"(?i)^\\s*professor\\s*\",\"Prof\")). \\\n",
    "withColumn(\"customer_name\",regexp_replace(col(\"customer_name\"),r\"(?i)^\\s*Mrs\\s*\",\"Mrs.\")). \\\n",
    "withColumn(\"customer_name\",regexp_replace(col(\"customer_name\"), r\"^(?i)Dr!\\s*([A-Za-z]+)\\*\\*?\\s*([A-Za-z]+)$\", \"DR.$1 $2\")). \\\n",
    "withColumn(\"customer_name\",regexp_replace(col(\"customer_name\"), r\"^(?i)Dr\\.([A-Za-z])\", \"Dr. $1\")). \\\n",
    "withColumn(\"customer_name\",regexp_replace(col(\"customer_name\"), r\"^\\s*(?i)Dr\\.\", \"Dr.\"))\n",
    "\n",
    "df_south = Named_final.withColumn(\"customer_name\", regexp_replace(col(\"customer_name\"), r\"(?i)^\\s*Prof\\s*([A-Za-z]+)\", \"Prof. $1\"))\n",
    "\n",
    "display(df_south)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e3a4a2fb-8cde-49bb-84d9-9e7f5802ef72",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# READING WEST DATA AND UNOINING WITH SOUTH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "70ba64eb-46cf-41c0-8812-eecbc183fa09",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "bronze_path_west = \"/mnt/mock_prajwal/bronze/Insurance_details_West_0\"\n",
    "\n",
    "df_west = spark.read.format(\"parquet\").load(bronze_path_west)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8359f360-c472-4913-8515-aacecfb140d5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(df_west)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "47e94e11-58e6-4861-887b-b9e7a91559dc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_west = df_west.withColumnRenamed(\"Customer ID\", \"customer_id\") \\\n",
    "       .withColumnRenamed(\"Customer Name\", \"customer_name\") \\\n",
    "       .withColumnRenamed(\"Customer_Segment\", \"customer_segment\") \\\n",
    "       .withColumnRenamed(\"Maritial_Status\", \"marital_status\") \\\n",
    "       .withColumnRenamed(\"Gender\", \"gender\") \\\n",
    "       .withColumnRenamed(\"Effective_Start_Dt\", \"effective_start_date\") \\\n",
    "       .withColumnRenamed(\"Effective_End_Dt\", \"effective_end_date\") \\\n",
    "       .withColumnRenamed(\"Policy_Type_Id\", \"policy_type_id\") \\\n",
    "       .withColumnRenamed(\"Policy_Id\", \"policy_id\") \\\n",
    "       .withColumnRenamed(\"Premium_Amt\", \"premium_amount\") \\\n",
    "       .withColumnRenamed(\"Policy_Start_Dt\", \"policy_start_date\") \\\n",
    "       .withColumnRenamed(\"Policy_End_Dt\", \"policy_end_date\") \\\n",
    "       .withColumnRenamed(\"Next_Premium_Dt\", \"next_premium_date\") \\\n",
    "       .withColumnRenamed(\"Actual_Premium_Paid_Dt\", \"actual_premium_paid_date\") \\\n",
    "       .withColumnRenamed(\"Country\", \"country\") \\\n",
    "       .withColumnRenamed(\"Region\", \"region\") \\\n",
    "       .withColumnRenamed(\"State or Province\", \"state\") \\\n",
    "       .withColumnRenamed(\"City\", \"city\") \\\n",
    "       .withColumnRenamed(\"Postal Code\", \"postal_code\") \\\n",
    "       .withColumnRenamed(\"Total_Policy_Amt\", \"total_policy_amount\") \\\n",
    "       .withColumnRenamed(\"Premium_Amt_Paid_TillDate\", \"premium_amt_paid_tilldate\")\n",
    "\n",
    "display(df_west)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f7d32b88-bfc0-478f-94eb-54630deb8a84",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "Named_df = df_west.withColumn(\"customer_name\",regexp_replace(col(\"customer_name\"),r\"(?i)^\\s*doctor\\s+\",\"Dr.\")).withColumn(\"customer_name\",regexp_replace(col(\"customer_name\"),r\"(?i)^\\s+professor\\s+\",\"Prof.\")).\\\n",
    "withColumn(\"customer_name\",regexp_replace(col(\"customer_name\"),r\"(?i)^\\s*Mistress\\s*\",\"Mrs\")) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "14897527-dd57-4fd4-b20a-7e8ba3ff77d1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "Named_final = Named_df.withColumn(\"customer_name\",regexp_replace(col(\"customer_name\"),r\"(?i)^\\s*doctor\\s*\",\"Dr\")). \\\n",
    "withColumn(\"customer_name\",regexp_replace(col(\"customer_name\"),r\"(?i)^\\s*professor\\s*\",\"Prof\")). \\\n",
    "withColumn(\"customer_name\",regexp_replace(col(\"customer_name\"),r\"(?i)^\\s*Mrs\\s*\",\"Mrs.\")). \\\n",
    "withColumn(\"customer_name\",regexp_replace(col(\"customer_name\"), r\"^(?i)Dr!\\s*([A-Za-z]+)\\*\\*?\\s*([A-Za-z]+)$\", \"DR.$1 $2\")). \\\n",
    "withColumn(\"customer_name\",regexp_replace(col(\"customer_name\"), r\"^(?i)Dr\\.([A-Za-z])\", \"Dr. $1\")). \\\n",
    "withColumn(\"customer_name\",regexp_replace(col(\"customer_name\"), r\"^\\s*(?i)Dr\\.\", \"Dr.\"))\n",
    "\n",
    "Named_final = Named_final.withColumn(\"customer_name\", regexp_replace(col(\"customer_name\"), r\"(?i)^\\s*Prof\\s*([A-Za-z]+)\", \"Prof. $1\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f6bc5541-16d2-4192-a9c3-f1e5a10fd034",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_west = Named_final.withColumn(\"DOB\", fix_dob_udf(col(\"DOB\")))\n",
    "\n",
    "display(df_west)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e81d6d05-f628-40f2-b197-55c5db06d13d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_west = df_west.withColumn(\"effective_start_date\", fix_dob_udf(col(\"effective_start_date\")))\n",
    "df_west = df_west.withColumn(\"effective_end_date\", fix_dob_udf(col(\"effective_end_date\")))\n",
    "\n",
    "df_west = df_west.withColumn(\"policy_start_date\", fix_dob_udf(col(\"policy_start_date\")))\n",
    "\n",
    "df_west = df_west.withColumn(\"policy_end_date\", fix_dob_udf_new(col(\"policy_end_date\")))\n",
    "\n",
    "df_new = df_west.withColumn(\"next_premium_date\", fix_dob_udf(col(\"next_premium_date\")))\n",
    "\n",
    "df_new = df_new.withColumn(\"actual_premium_paid_date\", fix_dob_udf(col(\"actual_premium_paid_date\")))\n",
    "\n",
    "# Standardize ZIP codes (Ensuring 5-digit numeric values)\n",
    "df_new = df_new.withColumn(\"postal_code\", regexp_replace(col(\"postal_code\"), \"[^0-9]\", \"\"))\n",
    "df_new = df_new.withColumn(\"postal_code\", lpad(col(\"postal_code\"), 5, \"0\"))\n",
    "\n",
    "df_new = df_new.withColumn(\"premium_amount\", col(\"premium_amount\").cast(\"integer\"))\n",
    "df_new = df_new.withColumn(\"total_policy_amount\", col(\"total_policy_amount\").cast(\"integer\"))\n",
    "df_new = df_new.withColumn(\"premium_amt_paid_tilldate\", col(\"premium_amt_paid_tilldate\").cast(\"integer\"))\n",
    "df_west = df_new.withColumn(\"country\", lit(\"USA\"))\n",
    "\n",
    "\n",
    "display(df_west)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "96840266-1fce-46c8-831b-684adf1d3e94",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_west = df_west.withColumn(\"actual_premium_paid_date\", when(col(\"actual_premium_paid_date\").isNull(), \"2010-01-01\").otherwise(col(\"actual_premium_paid_date\")))\n",
    "df_west = df_west.filter(col(\"customer_id\").isNotNull())\n",
    "\n",
    "null_counts = df_west.select([count(when(col(c).isNull(), c)).alias(c) for c in df_west.columns]) \n",
    "display(null_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "151f1ecc-849b-4434-8804-bb1c9f9e0ec9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_new = df_west.withColumn(\"age\", floor(datediff(col(\"policy_start_date\"), col(\"DOB\")) / 365))\n",
    "\n",
    "df_new = df_new.withColumn(\"effective_end_date\", col(\"policy_end_date\"))\n",
    "\n",
    "from pyspark.sql.functions import col, datediff, lit, floor\n",
    "\n",
    "# Assuming 'customer_start_date' is the column indicating when the customer started\n",
    "df_west = df_new.withColumn(\"customer_tenure_years\", \n",
    "                           floor(datediff(col(\"actual_premium_paid_date\"), col(\"policy_start_date\")) / 365).alias(\"customer_tenure_years\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f9b45c1f-26c5-45c4-9c5f-ba68438a4bfe",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(df_west)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f6af7d91-10fc-4f50-bcb4-f359ae2a33b6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_combined = df_south.union(df_west)\n",
    "display(df_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "803fc500-119a-471e-877b-22e317a2b2bd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, datediff, when\n",
    "\n",
    "\"\"\"\n",
    "Late Payment Category: Categorize payments based on how late they were made. \n",
    "1-30 days - Slightly Late\n",
    "31-90 days - Moderately Late\n",
    "91+ days - Severely Late\n",
    "Negative days - Paid Early\n",
    "\"\"\"\n",
    "\n",
    "df_combined = df_combined.withColumn(\"days_late\", datediff(col(\"actual_premium_paid_date\"), col(\"next_premium_date\")))\n",
    "df_combined = df_combined.withColumn(\"late_payment_category\", \n",
    "                                     when(col(\"days_late\") < 0, \"Paid Early\")\n",
    "                                     .when((col(\"days_late\") >= 0) & (col(\"days_late\") <= 30), \"Slightly Late\")\n",
    "                                     .when((col(\"days_late\") > 30) & (col(\"days_late\") <= 90), \"Moderately Late\")\n",
    "                                     .when(col(\"days_late\") > 90, \"Severely Late\"))\n",
    "\n",
    "display(df_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "df0e2ff1-8aa3-4c84-82f2-1c044a557ef0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "silver_path = \"/mnt/mock_prajwal/silver/Insurance_details_South_West\"\n",
    "\n",
    "\n",
    "df_combined.write.mode(\"overwrite\").format(\"delta\").partitionBy(\"ingestion_time\").option(\"overwriteSchema\", \"true\").save(silver_path)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Silver_Insurance_details_South_West",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
