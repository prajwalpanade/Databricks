{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aa1c0128-6d6f-48d4-9bdc-fb1d20f19608",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.window import Window\n",
    "from datetime import datetime\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c9f6ebca-b87c-4998-90ff-013af56ce97e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run ../logs/logs_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "94560eae-75da-4e16-9456-47f3aa837419",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run ../utilities/Futuredate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2bc70035-2074-4f43-9fd2-e3787ace6574",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run ../utilities/Pastdate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "27ad76d6-3596-4f6e-b511-d0931d5b2d63",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Define Paths\n",
    "bronze_path = \"/mnt/mock_prajwal/Healthcare_practice/bronze/\"\n",
    "silver_path = \"/mnt/mock_prajwal/Healthcare_practice/silver/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c838c30c-7a46-4a89-872e-2ce48a0cc4f7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# try block to handle exceptions\n",
    "try:\n",
    "    # check if the bronze path exists\n",
    "    if dbutils.fs.ls(bronze_path):\n",
    "        # get the list of files in the bronze path\n",
    "        files = [file.name for file in dbutils.fs.ls(bronze_path)]\n",
    "        \n",
    "        # check if 'PatientDetails day 1' exists in the files\n",
    "        if 'PatientDetails day 1/' in files:\n",
    "            # set file path and other file details\n",
    "            file_path = bronze_path + \"PatientDetails day 1\"\n",
    "            file_name = os.path.basename(file_path)\n",
    "            file_extension = file_name.split(\".\")[-1]\n",
    "            file_name = file_name.split(\".\")[0]\n",
    "            file_info = dbutils.fs.ls(file_path)[0]\n",
    "            file_size_kb = file_info.size / 1024\n",
    "            file_mod_time = datetime.fromtimestamp(file_info.modificationTime / 1000)\n",
    "            processed_by = dbutils.notebook.entry_point.getDbutils().notebook().getContext().tags().apply('user')\n",
    "            file_type = \"parquet\"  # Define file_type\n",
    "            Layer = \"silver\"\n",
    "            \n",
    "            # start time of the files\n",
    "            start_time = time.time()\n",
    "            log_message(file_path, file_type, file_size_kb, file_mod_time, None, \"PROCESSING\", 0, processed_by, f\"Reading Parquet File {file_name}\", Layer)\n",
    "            \n",
    "            # Load the parquet file into a DataFrame\n",
    "            df = spark.read.format(\"parquet\").load(bronze_path + \"PatientDetails day 1\")\n",
    "            \n",
    "            pastdate = udf(date_format_udf, DateType())\n",
    "            df = df.withColumn(\"dob\", pastdate(col(\"dob\")))\n",
    "\n",
    "            df = df.toDF(*[c.lower() for c in df.columns])\n",
    "\n",
    "            df = df.toDF(*[c.replace(\" \", \"\") for c in df.columns])\n",
    "\n",
    "            df = df.withColumn(\"title\", coalesce(col(\"title\"), lit(\"Mr.\")))\n",
    "            df = df.withColumn(\"gender\", coalesce(col(\"gender\"), lit(\"Male\")))\n",
    "\n",
    "\n",
    "            df = df.withColumn(\"gender\", regexp_replace(\"gender\", \"Oth\", \"Other\"))\n",
    "            df = df.withColumn(\"gender\", regexp_replace(\"gender\", \"M ale\", \"Male\"))\n",
    "            df = df.withColumn(\"gender\", regexp_replace(\"gender\", \"Fe male\", \"Female\"))\n",
    "\n",
    "            df = df.withColumn(\"gender\", regexp_replace(\"gender\", \"Otherer\", \"Other\"))\n",
    "\n",
    "            df = df.withColumn(\"title\", regexp_replace(\"title\", \"Doctor\", \"Dr.\"))\n",
    "            df = df.withColumn(\"title\", regexp_replace(\"title\", \"Miss\", \"Ms.\"))\n",
    "            df = df.withColumn(\"title\", regexp_replace(\"title\", \"Professor.\", \"Prof.\"))\n",
    "            df = df.withColumn(\"title\", regexp_replace(\"title\", \" Ms.\", \"Ms.\"))\n",
    "\n",
    "            df = df.select([when(col(c).isNull(), \"Unknow\").otherwise(col(c)).alias(c) if c.startswith(\"chronicconditions_\") or c in [\"address\", \"city\"] else col(c) for c in df.columns])\n",
    "\n",
    "            # Standardize ZIP codes (Ensuring 5-digit numeric values)\n",
    "            df = df.withColumn(\"zipcode\", regexp_replace(col(\"zipcode\"), \"[^0-9]\", \"\"))\n",
    "            df = df.withColumn(\"zipcode\", lpad(col(\"zipcode\"), 5, \"0\"))\n",
    "\n",
    "\n",
    "            # Ensure email is correctly formatted\n",
    "            df = df.withColumn('emailaddress', regexp_replace('emailaddress', r'[^a-zA-Z0-9@._-]', ''))\n",
    "\n",
    "            # Standardize phone numbers (Ensuring numeric values)\n",
    "            df = df.withColumn(\"contactnumber\", regexp_replace(col(\"contactnumber\"), \"[^0-9]\", \"\"))\n",
    "\n",
    "            df = df.withColumn(\"cancerhistory\", \n",
    "                            when(col(\"cancerhistory\") == \"TRUE\", \"Yes\")\n",
    "                            .when(col(\"cancerhistory\") == \"0\", \"No\")\n",
    "                            .when(col(\"cancerhistory\") == \"1\", \"Yes\")\n",
    "                            .otherwise(col(\"cancerhistory\")))\n",
    "\n",
    "            df = df.withColumn(\"anytransplants\", \n",
    "                            when(col(\"anytransplants\") == \"FALSE\", \"No\")\n",
    "                            .otherwise(col(\"anytransplants\")))\n",
    "\n",
    "            df = df.withColumn(\"smoker\", \n",
    "                            when(col(\"smoker\") == \"0\", \"No\")\n",
    "                            .when(col(\"smoker\") == \"1\", \"Yes\")\n",
    "                            .otherwise(col(\"smoker\")))\n",
    "\n",
    "            df = df.withColumn(\"dob\", when(col(\"dob\").isNull(), lit(\"1999-01-01\")).otherwise(col(\"dob\")).cast(\"date\"))\n",
    "            df = df.withColumn(\"contactnumber\", when(col(\"contactnumber\").isNull(), lit(\"00000000\")).otherwise(col(\"contactnumber\")))\n",
    "\n",
    "            # Record count and processing time\n",
    "            record_count = df.count()\n",
    "            processing_time_sec = int(time.time() - start_time)\n",
    "            \n",
    "            # Final status\n",
    "            log_message(file_path, file_type, file_size_kb, file_mod_time, record_count, \"COMPLETED\", processing_time_sec, processed_by, f\"Successfully processed {file_path}\", Layer)\n",
    "\n",
    "            df.write.mode(\"overwrite\").format(\"delta\").partitionBy(\"ingestion_time\").option(\"overwriteSchema\", \"true\").save(silver_path + \"PatientDetails day 1\")\n",
    "# handle exceptions\n",
    "except Exception as e:\n",
    "    processing_time_sec = int(time.time() - start_time)\n",
    "    log_message(file_path, file_type, file_size_kb, file_mod_time, 0, \"FAILED\", processing_time_sec, processed_by, f\"Error processing file {file_path}: {str(e)}\", Layer)\n",
    "    raise e\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ecaa6699-da80-45b4-8c0c-8c22e7b389e6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Read the data from the silver layer\n",
    "df_silver_admissions = spark.read.format(\"delta\").load(silver_path + \"PatientDetails day 1\")\n",
    "display(df_silver_admissions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f023a64b-141c-4c9f-b5e6-4f11fb4a7616",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "log_path = \"/mnt/mock_prajwal/Healthcare_practice/logs\"\n",
    "df_logs = spark.read.format(\"delta\").load(log_path)\n",
    "df_logs_today = df_logs.filter(df_logs['processed_time'].cast(\"date\") == \"2025-05-19\")\n",
    "display(df_logs_today)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bf3131b0-9cbb-42ea-94e7-ad2005f9be7c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "857fa4a9-ffe4-408c-bea6-280da03562dd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f947e7b9-2cf2-4476-ba1b-2d4bd6da8521",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "973f88b5-f386-4f29-95ac-c92e2d282519",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "075f4abb-a2ee-4434-95e7-e0f290413e66",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "20fa5f9f-3d1c-49e9-85f7-728ca873be88",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "410ae66e-fe71-4a07-a1dc-6d03ab6ebddf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "03137182-e615-4341-a998-221eb3681f7b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "44c12306-5f43-48a7-a861-82084acdb274",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# from pyspark.sql.functions import coalesce, lit\n",
    "\n",
    "# df = df.withColumn(\"title\", coalesce(col(\"title\"), lit(\"Mr.\")))\n",
    "# df = df.withColumn(\"gender\", coalesce(col(\"gender\"), lit(\"Male\")))\n",
    "# display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0d151f71-6acb-4573-884e-beabe4af856b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# from pyspark.sql.functions import regexp_replace\n",
    "\n",
    "# df = df.withColumn(\"gender\", regexp_replace(\"gender\", \"Oth\", \"Other\"))\n",
    "# df = df.withColumn(\"gender\", regexp_replace(\"gender\", \"M ale\", \"Male\"))\n",
    "# df = df.withColumn(\"gender\", regexp_replace(\"gender\", \"Fe male\", \"Female\"))\n",
    "# display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e6c1545a-60c0-468f-a9e7-d1ea269f03d2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# df = df.withColumn(\"gender\", regexp_replace(\"gender\", \"Otherer\", \"Other\"))\n",
    "# display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "720da0db-92bc-4296-98fc-b4e38d2b577b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# from pyspark.sql.functions import regexp_replace\n",
    "\n",
    "# df = df.withColumn(\"title\", regexp_replace(\"title\", \"Doctor\", \"Dr.\"))\n",
    "# df = df.withColumn(\"title\", regexp_replace(\"title\", \"Miss\", \"Ms.\"))\n",
    "# df = df.withColumn(\"title\", regexp_replace(\"title\", \"Professor.\", \"Prof.\"))\n",
    "# df = df.withColumn(\"title\", regexp_replace(\"title\", \" Ms.\", \"Ms.\"))\n",
    "# display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0e3937a8-053c-4118-bd64-578c7e90b911",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# from pyspark.sql.functions import when\n",
    "\n",
    "# df = df.select([when(col(c).isNull(), \"Unknow\").otherwise(col(c)).alias(c) if c.startswith(\"chronicconditions_\") or c in [\"address\", \"city\"] else col(c) for c in df.columns])\n",
    "# display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a197b01f-de9b-4ffd-8eb2-7be8cd694d33",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# df = df.withColumn(\"cancerhistory\", \n",
    "#                    when(col(\"cancerhistory\") == \"TRUE\", \"Yes\")\n",
    "#                    .when(col(\"cancerhistory\") == \"0\", \"No\")\n",
    "#                    .when(col(\"cancerhistory\") == \"1\", \"Yes\")\n",
    "#                    .otherwise(col(\"cancerhistory\")))\n",
    "\n",
    "# display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6eb0906d-a165-47c3-9ad9-01b905999685",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# df = df.withColumn(\"anytransplants\", \n",
    "#                    when(col(\"anytransplants\") == \"FALSE\", \"No\")\n",
    "#                    .otherwise(col(\"anytransplants\")))\n",
    "\n",
    "# display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c52af1d4-2982-46f6-ad22-b7576d2c4277",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# df = df.withColumn(\"smoker\", \n",
    "#                    when(col(\"smoker\") == \"0\", \"No\")\n",
    "#                    .when(col(\"smoker\") == \"1\", \"Yes\")\n",
    "#                    .otherwise(col(\"smoker\")))\n",
    "\n",
    "# display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bdbb1886-7513-486a-b097-641612e16b71",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# from pyspark.sql.functions import col, lit, when\n",
    "\n",
    "# df = df.withColumn(\"dob\", when(col(\"dob\").isNull(), lit(\"1999-01-01\")).otherwise(col(\"dob\")).cast(\"date\"))\n",
    "# df = df.withColumn(\"contactnumber\", when(col(\"contactnumber\").isNull(), lit(\"00000000\")).otherwise(col(\"contactnumber\")))\n",
    "\n",
    "# display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ec29e8e6-3197-46cd-94e2-98ef607b7ccf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# from pyspark.sql.functions import col, sum\n",
    "\n",
    "# null_counts = df.select([sum(col(c).isNull().cast(\"int\")).alias(c) for c in df.columns])\n",
    "# display(null_counts)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Silver_PatientDetails_day1",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
