{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f48ecf81-3ef4-4794-b5f7-2a76f6929570",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Importing the required libraries\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.window import Window\n",
    "import os\n",
    "from datetime import datetime\n",
    "import time\n",
    "from pyspark.sql.types import StructType, StructField, StringType, DoubleType, TimestampType, IntegerType\n",
    "import pyspark.sql.functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9f2cd316-b677-48e7-bd5d-16a01fa36119",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run ../logs/logs_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "503a33d6-50d0-424c-9d3e-32e141502a62",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Define Paths\n",
    "source_path = \"/mnt/mock_prajwal/Healthcare_practice/source_file/Admissions.csv\"\n",
    "bronze_path = \"/mnt/mock_prajwal/Healthcare_practice/bronze/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6bac0edf-cbae-4b70-b789-da84f76c1494",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    # Initialize start time\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Log file details\n",
    "    file_path = source_path\n",
    "    file_name = os.path.basename(file_path)\n",
    "    file_extension = file_name.split(\".\")[-1]\n",
    "    file_name = file_name.split(\".\")[0]\n",
    "    file_info = dbutils.fs.ls(file_path)[0]\n",
    "    file_size_kb = file_info.size / 1024\n",
    "    file_mod_time = datetime.fromtimestamp(file_info.modificationTime / 1000)\n",
    "    processed_by = dbutils.notebook.entry_point.getDbutils().notebook().getContext().tags().apply('user')\n",
    "    file_type = \"csv\"  # Define file_type\n",
    "\n",
    "    Layer = \"Bronze\"\n",
    "\n",
    "    # Log start of processing\n",
    "    log_message(file_path, file_type, file_size_kb, file_mod_time, None, \"PROCESSING\", 0, processed_by, f\"Reading CSV File {file_name}\", Layer)\n",
    "    \n",
    "    # Read CSV file\n",
    "    schema = StructType([\n",
    "    StructField(\"Patient ID\", StringType(), True),\n",
    "    StructField(\"Doctor ID\", StringType(), True),\n",
    "    StructField(\"Department\", StringType(), True),\n",
    "    StructField(\"Admission Date\", StringType(), True),\n",
    "    StructField(\"Discharge Date\", StringType(), True),\n",
    "    StructField(\"ingestion_time\", TimestampType(), True)])\n",
    "\n",
    "    df = spark.read.option(\"delimiter\", \",\").option(\"inferSchema\", \"false\").schema(schema).csv(source_path, header=False, quote='\"', escape='\"')\n",
    "    \n",
    "    # Add ingestion_time column\n",
    "    df = df.withColumn(\"ingestion_time\", current_timestamp())\n",
    "    \n",
    "    # Record count and processing time\n",
    "    record_count = df.count()\n",
    "    processing_time_sec = int(time.time() - start_time)\n",
    "\n",
    "    # Write to Parquet\n",
    "    df.write.format(\"parquet\").mode(\"overwrite\").save(bronze_path + file_name)\n",
    "\n",
    "    # Final status\n",
    "    log_message(file_path, file_type, file_size_kb, file_mod_time, record_count, \"COMPLETED\", processing_time_sec, processed_by, f\"Successfully processed {file_path}\", Layer)\n",
    "\n",
    "except Exception as e:\n",
    "    processing_time_sec = int(time.time() - start_time)\n",
    "    log_message(file_path, file_type, file_size_kb, file_mod_time, 0, \"FAILED\", processing_time_sec, processed_by, f\"Error processing file {file_path}: {str(e)}\", Layer)\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fd67b08d-2465-4b91-91f3-581b8f3ef739",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_bronze = spark.read.format(\"parquet\").load(bronze_path + file_name)\n",
    "display(df_bronze)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5cb444c7-46c2-4360-9349-a1e08474659f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "log_path = \"/mnt/mock_prajwal/Healthcare_practice/logs\"\n",
    "df_logs = spark.read.format(\"delta\").load(log_path)\n",
    "df_logs_today = df_logs.filter(df_logs['processed_time'].cast(\"date\") == \"2025-05-19\")\n",
    "display(df_logs_today)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Bronze_Admissions.",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
