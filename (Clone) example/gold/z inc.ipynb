{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7df138e2-86e3-4f44-8adb-815994782200",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import monotonically_increasing_id, col, count, row_number, lit, current_timestamp, coalesce, max\n",
    "from pyspark.sql.window import Window\n",
    "from delta.tables import DeltaTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "62620b21-4bb2-4aae-8adc-9b5865fc4b00",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Define Paths\n",
    "silver_path = \"/mnt/mock_prajwal/Healthcare_practice/silver/\"\n",
    "gold_path = \"/mnt/mock_prajwal/Healthcare_practice/gold/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7536cbe3-bf8e-4311-9b2f-9e3d086d17b3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "df_patinent = spark.read.format(\"delta\").load(silver_path + \"PatientDetails day 1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a3ad6f8a-d525-4d6e-b22b-ecf95dd5d15e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import when, col\n",
    "\n",
    "df_selected = df_patinent.withColumn(\n",
    "    \"bmi_status\",\n",
    "    when(col(\"bmi\") < 18.5, \"Underweight\")\n",
    "    .when((col(\"bmi\") >= 18.5) & (col(\"bmi\") <= 24.9), \"Normal weight\")\n",
    "    .when((col(\"bmi\") >= 25.0) & (col(\"bmi\") <= 29.9), \"Overweight\")\n",
    "    .when((col(\"bmi\") >= 30.0) & (col(\"bmi\") <= 34.9), \"Obesity (Class 1)\")\n",
    "    .when((col(\"bmi\") >= 35.0) & (col(\"bmi\") <= 39.9), \"Obesity (Class 2)\")\n",
    "    .when(col(\"bmi\") >= 40.0, \"Obesity (Class 3 - Severe/Extreme)\")\n",
    ")\n",
    "\n",
    "df_selected = df_selected.withColumn(\n",
    "    \"hba1c_status\",\n",
    "    when(col(\"hba1c\") < 5.7, \"Normal\")\n",
    "    .when((col(\"hba1c\") >= 5.7) & (col(\"hba1c\") <= 6.4), \"Pre-Diabetes\")\n",
    "    .when(col(\"hba1c\") >= 6.5, \"Diabetes\")\n",
    ")\n",
    "\n",
    "display(df_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "59453a75-c7d0-4ca2-bf4c-dcdde39ed853",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_selected = df_selected.drop(\"bmi\", \"hba1c\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "de9f9c18-91c9-42dd-8ccd-d87566a0b443",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# ïƒ¼\tIdentify high-risk patients for specialized attention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b391ed36-98f9-467e-b7ee-65042f797fcd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_high_risk_patients = df_selected.filter(\n",
    "    (col(\"bmi_status\").like(\"Obesity%\")) & \n",
    "    (col(\"hba1c_status\") == \"Diabetes\") & \n",
    "    (col(\"heartissues\") == \"Yes\") & \n",
    "    (col(\"anytransplants\") == \"Yes\") & \n",
    "    (col(\"cancerhistory\") == \"Yes\") & \n",
    "    (col(\"numberofmajorsurgeries\") > 2) & \n",
    "    (col(\"smoker\") == \"Yes\")\n",
    ")\n",
    "\n",
    "display(df_high_risk_patients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "38c27152-dcee-4e9f-b914-a89bbd1c9be5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_selected = df_selected.select([\n",
    "    \"patientid\", \"title\", \"name\", \"dob\", \"gender\", \"bloodtype\", \"chronicconditions\", \n",
    "    \"contactnumber\", \"emailaddress\", \"profession\", \"address\", \"city\", \"state\", \"country\", \n",
    "    \"zipcode\", \"heartissues\", \"anytransplants\", \"cancerhistory\", \"numberofmajorsurgeries\", \n",
    "    \"smoker\",\"bmi_status\",\"hba1c_status\"\n",
    "]).dropDuplicates(['patientid'])\n",
    "\n",
    "window_spec = Window.orderBy(\"patientid\")\n",
    "\n",
    "df_selected = df_selected.withColumn(\"patient_key\", row_number().over(window_spec))\n",
    "\n",
    "display(df_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c6230d4c-6f0c-410b-87a5-614db58927f8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType, DateType\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"patientid\", StringType(), True),\n",
    "    StructField(\"title\", StringType(), True),\n",
    "    StructField(\"name\", StringType(), True),\n",
    "    StructField(\"dob\", DateType(), True),\n",
    "    StructField(\"gender\", StringType(), True),\n",
    "    StructField(\"bloodtype\", StringType(), True),\n",
    "    StructField(\"chronicconditions\", StringType(), True),\n",
    "    StructField(\"contactnumber\", StringType(), True),\n",
    "    StructField(\"emailaddress\", StringType(), True),\n",
    "    StructField(\"profession\", StringType(), True),\n",
    "    StructField(\"address\", StringType(), True),\n",
    "    StructField(\"city\", StringType(), True),\n",
    "    StructField(\"state\", StringType(), True),\n",
    "    StructField(\"country\", StringType(), True),\n",
    "    StructField(\"zipcode\", StringType(), True),\n",
    "    StructField(\"heartissues\", StringType(), True),\n",
    "    StructField(\"anytransplants\", StringType(), True),\n",
    "    StructField(\"cancerhistory\", StringType(), True),\n",
    "    StructField(\"numberofmajorsurgeries\", IntegerType(), True),\n",
    "    StructField(\"smoker\", StringType(), True),\n",
    "    StructField(\"bmi_status\", StringType(), True),\n",
    "    StructField(\"hba1c_status\", StringType(), True),\n",
    "    StructField(\"patient_key\", IntegerType(), False),\n",
    "    StructField(\"start_date\", TimestampType(), False),\n",
    "    StructField(\"end_date\", TimestampType(), True),\n",
    "    StructField(\"is_active\", BooleanType(), False),\n",
    "    StructField(\"last_modified\", TimestampType(), False)\n",
    "])\n",
    "\n",
    "# Create the schema if it does not exist\n",
    "spark.sql(\"CREATE SCHEMA IF NOT EXISTS Prajwal_Mock\")\n",
    "\n",
    "# Create the table with the specified schema\n",
    "spark.sql(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS Prajwal_Mock.Dim_Patient (\n",
    "        patientid STRING,\n",
    "        title STRING,\n",
    "        name STRING,\n",
    "        dob DATE,\n",
    "        gender STRING,\n",
    "        bloodtype STRING,\n",
    "        chronicconditions STRING,\n",
    "        contactnumber STRING,\n",
    "        emailaddress STRING,\n",
    "        profession STRING,\n",
    "        address STRING,\n",
    "        city STRING,\n",
    "        state STRING,\n",
    "        country STRING,\n",
    "        zipcode STRING,\n",
    "        heartissues STRING,\n",
    "        anytransplants STRING,\n",
    "        cancerhistory STRING,\n",
    "        numberofmajorsurgeries INT,\n",
    "        smoker STRING,\n",
    "        bmi_status STRING,\n",
    "        hba1c_status STRING,\n",
    "        patient_key INT NOT NULL,\n",
    "        start_date TIMESTAMP NOT NULL,\n",
    "        end_date TIMESTAMP,\n",
    "        is_active BOOLEAN NOT NULL,\n",
    "        last_modified TIMESTAMP NOT NULL\n",
    "    )\n",
    "        USING DELTA \n",
    "    LOCATION \"/mnt/mock_prajwal/Healthcare_practice/gold/dim_patient\"\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "91d7d4d3-4bb6-454e-9041-08a1aa311c40",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import coalesce, max, lit, row_number, col, current_timestamp\n",
    "from pyspark.sql.window import Window\n",
    "from delta.tables import DeltaTable\n",
    "\n",
    "# Load target table\n",
    "target_df = spark.read.table(\"Prajwal_Mock.Dim_Patient\")\n",
    "\n",
    "# Check if 'patient_key' column exists in the target table\n",
    "if 'patient_key' in target_df.columns:\n",
    "    # Finding max of previous data from table\n",
    "    max_key = target_df.agg(coalesce(max(\"patient_key\"), lit(0))).collect()[0][0]\n",
    "else:\n",
    "    max_key = 0\n",
    "\n",
    "# Define window specification\n",
    "window_spec = Window.orderBy(\"patientid\")\n",
    "\n",
    "# Add row number and patient_key\n",
    "source_df_keyed = df_selected \\\n",
    "    .withColumn(\"rn\", row_number().over(window_spec)) \\\n",
    "    .withColumn(\"patient_key\", col(\"rn\") + lit(max_key)) \\\n",
    "    .drop(\"rn\")\n",
    "\n",
    "# Add audit columns to source\n",
    "source_df_audit_col = source_df_keyed \\\n",
    "    .withColumn(\"start_date\", current_timestamp()) \\\n",
    "    .withColumn(\"end_date\", lit(None).cast(\"timestamp\")) \\\n",
    "    .withColumn(\"is_active\", lit(True)) \\\n",
    "    .withColumn(\"last_modified\", current_timestamp())\n",
    "\n",
    "# Convert target to DeltaTable\n",
    "target_table = DeltaTable.forName(spark, \"Prajwal_Mock.Dim_Patient\")\n",
    "\n",
    "# Merge condition (on business key and active rows)\n",
    "merge_condition = \"target.patientid = source.patientid AND target.is_active = true\"\n",
    "\n",
    "# Perform Expiration\n",
    "target_table.alias(\"target\") \\\n",
    "    .merge(source_df_audit_col.alias(\"source\"), merge_condition) \\\n",
    "    .whenMatchedUpdate(\n",
    "        condition=\"target.name != source.name OR \"\n",
    "                  \"target.dob != source.dob OR \"\n",
    "                  \"target.gender != source.gender OR \"\n",
    "                  \"target.bloodtype != source.bloodtype OR \"\n",
    "                  \"target.contactnumber != source.contactnumber OR \"\n",
    "                  \"target.emailaddress != source.emailaddress OR \"\n",
    "                  \"target.address != source.address OR \"\n",
    "                  \"target.city != source.city OR \"\n",
    "                  \"target.state != source.state OR \"\n",
    "                  \"target.country != source.country OR \"\n",
    "                  \"target.zipcode != source.zipcode\",\n",
    "        set={\n",
    "            \"end_date\": current_timestamp(),\n",
    "            \"is_active\": lit(False),\n",
    "            \"last_modified\": current_timestamp()\n",
    "        }\n",
    "    ).execute()\n",
    "\n",
    "# Insert records with new keys (new business keys that never existed)\n",
    "updated_target_df = spark.read.table(\"Prajwal_Mock.Dim_Patient\").filter(\"is_active=true\").select(\"patientid\")\n",
    "insert_df = source_df_audit_col.join(updated_target_df, on=\"patientid\", how=\"left_anti\")\n",
    "\n",
    "insert_df.write.format(\"delta\").mode(\"append\").option(\"mergeSchema\", \"true\").save(\"/mnt/mock_prajwal/Healthcare_practice/gold/dim_patient\")\n",
    "\n",
    "# Ensure the schema matches the target table\n",
    "# insert_df = insert_df.select(*[col for col in target_df.columns if col in insert_df.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "00036d96-e4ef-4001-971e-44476f3ad1aa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Count the number of updated records\n",
    "updated_count = target_table.toDF().filter(\"is_active = false AND last_modified = current_timestamp()\").count()\n",
    "\n",
    "# Count the number of inserted records\n",
    "inserted_count = insert_df.count()\n",
    "\n",
    "# Display the counts\n",
    "display(spark.createDataFrame([(updated_count, inserted_count)], [\"Updated Records\", \"Inserted Records\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "73fcf389-8972-44a0-93b4-e1cf8bf90c13",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_dim_patient = spark.read.format(\"delta\").load(\"/mnt/mock_prajwal/Healthcare_practice/gold/dim_patient\")\n",
    "display(df_dim_patient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "320341da-e4af-49e8-abc5-c5623983945a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# spark.sql(\"DROP TABLE IF EXISTS Prajwal_Mock.Dim_Patient\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c0469f79-32d6-4aa9-9457-1e1ed577a441",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# df_adm = spark.read.format(\"delta\").load(silver_path + \"Admissions\")\n",
    "# df_bill = spark.read.format(\"delta\").load(silver_path + \"Billing\")\n",
    "# df_proc = spark.read.format(\"delta\").load(silver_path + \"Procedures\")\n",
    "# df_test = spark.read.format(\"delta\").load(silver_path + \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "83d69e0a-b912-4287-96c8-c15b4bfd7bfb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# df_adm.printSchema()\n",
    "# df_bill.printSchema()\n",
    "# df_proc.printSchema()\n",
    "# df_test.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "79652f38-52b4-4ca5-8508-48449d2fca2e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "z inc",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
