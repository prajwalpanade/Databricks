{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4c0ca67b-529b-4da6-b427-c42dcd47e4d1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import monotonically_increasing_id, col, count, row_number, lit, current_timestamp, coalesce, max\n",
    "from pyspark.sql.window import Window\n",
    "from delta.tables import DeltaTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9bb45c25-6922-4e43-94b8-e6c071e741b6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "silver_path = \"/mnt/mock_prajwal/Mock2/silver/\"\n",
    "gold_path = \"/mnt/mock_prajwal/Mock2/gold/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7e961032-324c-4c53-84e7-b4dcbff64cdc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = spark.read.format(\"delta\").load(silver_path + \"FF_Customer_Details_Day0\")\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ad655f0c-d96d-428a-96eb-8677973f16e9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "sales_rep_dim = df.select(\"sales_rep_id\", \"sales_rep_name\").dropDuplicates(['sales_rep_id'])\n",
    "sales_rep_dim = sales_rep_dim.withColumn(\"sales_rep_key\", row_number().over(Window.orderBy(col(\"sales_rep_id\"))))\n",
    "\n",
    "display(sales_rep_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d942195a-d490-40a5-9606-00b613509c12",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Define the sales schema\n",
    "sales_schema = StructType([\n",
    "    StructField(\"sales_rep_id\", IntegerType(), True),\n",
    "    StructField(\"sales_rep_name\", StringType(), True),\n",
    "    StructField(\"sales_rep_key\", IntegerType(), False)\n",
    "])\n",
    "\n",
    "# Create the schema if it does not exist\n",
    "spark.sql(\"CREATE SCHEMA IF NOT EXISTS Prajwal_Mock\")\n",
    "\n",
    "# Create the table if it does not exist\n",
    "spark.sql(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS Prajwal_Mock.Dim_Sales_Rep (\n",
    "        sales_rep_id INTEGER,\n",
    "        sales_rep_name STRING,\n",
    "        sales_rep_key INTEGER NOT NULL\n",
    "    )\n",
    "    USING DELTA \n",
    "    LOCATION \"/mnt/mock_prajwal/Mock2/gold/Dim_Sales_rep\"\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d2289ec8-f7b7-45eb-a48e-d6e1b2f7cadc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# # Check schema for sales_rep_dim DataFrame\n",
    "# sales_rep_dim_schema = sales_rep_dim.schema\n",
    "\n",
    "# # # Check schema for silver_df DataFrame\n",
    "# # silver_df = spark.read.format(\"delta\").load(silver_path + \"FF_Customer_Details_Day0\")\n",
    "# # silver_df_schema = silver_df.schema\n",
    "\n",
    "# # Check schema for Prajwal_Mock.Dim_Sales_Rep table\n",
    "# dim_sales_rep_schema = spark.sql(\"DESCRIBE Prajwal_Mock.Dim_Sales_Rep\")\n",
    "\n",
    "# # Display schemas\n",
    "# display(sales_rep_dim_schema)\n",
    "# display(silver_df_schema)\n",
    "# display(dim_sales_rep_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9b53a493-f19c-4e2d-bc0f-2466d820d631",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "sales_rep_dim.write.option(\"mergeSchema\", \"true\").mode(\"overwrite\").format(\"delta\").save(gold_path + \"Dim_Sales_rep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8b11e942-679a-4960-866a-1d1dea787d54",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Count records in the gold layer\n",
    "gold_count = sales_rep_dim.count()\n",
    "\n",
    "# Assuming silver layer is stored in a DataFrame named silver_df\n",
    "silver_df = spark.read.format(\"delta\").load(silver_path + \"FF_Customer_Details_Day0\")\n",
    "silver_count = silver_df.count()\n",
    "\n",
    "# Display counts\n",
    "display(spark.createDataFrame([(silver_count, gold_count)], [\"Silver Layer Count\", \"Gold Layer Count\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5868be85-a06b-420f-8cd8-fbe023720751",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# spark.sql(\"DROP TABLE IF EXISTS Prajwal_Mock.Dim_Sales_Rep\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Sales_Rep_dim",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
